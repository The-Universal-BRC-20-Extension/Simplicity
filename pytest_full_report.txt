============================= test session starts ==============================
platform linux -- Python 3.11.2, pytest-8.4.1, pluggy-1.6.0 -- /home/indexer/.local/share/virtualenvs/simplicity-OFpnhncL/bin/python
cachedir: .pytest_cache
rootdir: /home/indexer/simplicity
plugins: docker-3.2.3, asyncio-1.0.0, anyio-4.9.0, cov-6.2.1
asyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collecting ... collected 638 items

scripts/utilities/test_setup.py::test_imports PASSED                     [  0%]
scripts/utilities/test_setup.py::test_critical_rules_compliance PASSED   [  0%]
scripts/utilities/test_setup.py::test_database_schema PASSED             [  0%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_registration_and_processing[sqlite] FAILED [  0%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_registration_and_processing[postgresql] FAILED [  0%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_operations_retrieval[sqlite] FAILED [  0%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_operations_retrieval[postgresql] FAILED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_legacy_transfers_retrieval[sqlite] FAILED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_legacy_transfers_retrieval[postgresql] FAILED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_error_handling[sqlite] PASSED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_error_handling[postgresql] PASSED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_case_sensitivity[sqlite] FAILED [  1%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_case_sensitivity[postgresql] FAILED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_empty_results_handling[sqlite] FAILED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_empty_results_handling[postgresql] FAILED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_database_error_handling[sqlite] FAILED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_database_error_handling[postgresql] FAILED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_registry_error_handling[sqlite] PASSED [  2%]
tests/integration/test_opi_integration.py::TestOpiIntegration::test_registry_error_handling[postgresql] PASSED [  2%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_deploy_success_real_validation[sqlite] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_deploy_success_real_validation[postgresql] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_deploy_blocked_by_legacy_real_validation[sqlite] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_deploy_blocked_by_legacy_real_validation[postgresql] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_mint_success_real_validation[sqlite] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_mint_success_real_validation[postgresql] PASSED [  3%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_transfer_success_real_validation[sqlite] PASSED [  4%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_transfer_success_real_validation[postgresql] PASSED [  4%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_validation_error_real_validation[sqlite] PASSED [  4%]
tests/integration/test_real_validation.py::TestRealValidationIntegration::test_validation_error_real_validation[postgresql] PASSED [  4%]
tests/test_api_integration.py::test_get_tickers[sqlite] FAILED           [  4%]
tests/test_api_integration.py::test_get_tickers[postgresql] FAILED       [  4%]
tests/test_api_integration.py::test_get_ticker_not_found[sqlite] FAILED  [  5%]
tests/test_api_integration.py::test_get_ticker_not_found[postgresql] FAILED [  5%]
tests/test_api_integration.py::test_get_ticker_success[sqlite] FAILED    [  5%]
tests/test_api_integration.py::test_get_ticker_success[postgresql] FAILED [  5%]
tests/test_api_integration.py::test_get_ticker_holders[sqlite] FAILED    [  5%]
tests/test_api_integration.py::test_get_ticker_holders[postgresql] FAILED [  5%]
tests/test_api_integration.py::test_get_ticker_transactions[sqlite] FAILED [  5%]
tests/test_api_integration.py::test_get_ticker_transactions[postgresql] FAILED [  6%]
tests/test_api_integration.py::test_get_address_balances[sqlite] FAILED  [  6%]
tests/test_api_integration.py::test_get_address_balances[postgresql] FAILED [  6%]
tests/test_api_integration.py::test_get_address_transactions[sqlite] FAILED [  6%]
tests/test_api_integration.py::test_get_address_transactions[postgresql] FAILED [  6%]
tests/test_api_integration.py::test_health_check[sqlite] FAILED          [  6%]
tests/test_api_integration.py::test_health_check[postgresql] FAILED      [  7%]
tests/test_api_integration.py::test_pagination_validation[sqlite] FAILED [  7%]
tests/test_api_integration.py::test_pagination_validation[postgresql] FAILED [  7%]
tests/test_api_integration.py::test_long_ticker_valid_but_not_found[sqlite] FAILED [  7%]
tests/test_api_integration.py::test_long_ticker_valid_but_not_found[postgresql] FAILED [  7%]
tests/test_api_integration.py::test_invalid_bitcoin_address[sqlite] PASSED [  7%]
tests/test_api_integration.py::test_invalid_bitcoin_address[postgresql] PASSED [  7%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_creation PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_get_existing PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_update_mint PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_update_transfer_sufficient PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_update_transfer_insufficient PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_update_transfer_exact PASSED [  8%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_large_amounts PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_zero_operations PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_get_total_supply_empty PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_get_total_supply_with_balances PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_concurrent_access PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_string_amounts_only PASSED [  9%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_decimal_amounts PASSED [ 10%]
tests/test_balance_management.py::TestBalanceManagement::test_balance_precision_handling PASSED [ 10%]
tests/test_brc20_classification.py::test_non_brc20_op_return_handling PASSED [ 10%]
tests/test_brc20_classification.py::test_valid_json_invalid_protocol_handling PASSED [ 10%]
tests/test_brc20_classification.py::test_non_json_op_return_handling PASSED [ 10%]
tests/test_brc20_classification.py::test_valid_brc20_op_is_processed PASSED [ 10%]
tests/test_brc20_classification.py::test_no_op_return_handling PASSED    [ 10%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_ticker_info PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_operation PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_address_balance PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_holder_info PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_transaction_operation PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_transaction_operation_mint PASSED [ 11%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_transaction_operation_deploy PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_transaction_operation_transfer PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_indexer_status PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_paginated_response PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_paginated_response_direct_list PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_unix PASSED [ 12%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_datetime PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_string PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_string_with_z PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_none PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_format_timestamp_invalid PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_calculate_remaining_supply PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_calculate_remaining_supply_zero PASSED [ 13%]
tests/test_data_transformation.py::TestDataTransformation::test_calculate_remaining_supply_exceeded PASSED [ 14%]
tests/test_data_transformation.py::TestDataTransformation::test_calculate_remaining_supply_invalid_input PASSED [ 14%]
tests/test_data_transformation.py::TestDataTransformation::test_add_ticker_to_holders PASSED [ 14%]
tests/test_data_transformation.py::TestDataTransformation::test_add_ticker_to_operations PASSED [ 14%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_with_missing_fields PASSED [ 14%]
tests/test_data_transformation.py::TestDataTransformation::test_transform_empty_data PASSED [ 14%]
tests/test_deploy_validation_fix.py::TestDeployValidationFix::test_deploy_with_no_standard_outputs_is_valid PASSED [ 15%]
tests/test_deploy_validation_fix.py::TestDeployValidationFix::test_deploy_with_standard_outputs_is_also_valid PASSED [ 15%]
tests/test_deploy_validation_fix.py::TestDeployValidationFix::test_mint_with_no_standard_outputs_is_invalid PASSED [ 15%]
tests/test_deploy_validation_fix.py::TestDeployValidationFix::test_mint_with_standard_outputs_is_valid PASSED [ 15%]
tests/test_deploy_validation_fix.py::TestDeployValidationFix::test_transfer_with_no_standard_outputs_is_invalid PASSED [ 15%]
tests/test_error_handler.py::TestErrorHandler::test_handle_rpc_error PASSED [ 15%]
tests/test_error_handler.py::TestErrorHandler::test_handle_database_error PASSED [ 15%]
tests/test_error_handler.py::TestErrorHandler::test_handle_validation_error PASSED [ 16%]
tests/test_error_handler.py::TestErrorHandler::test_should_retry PASSED  [ 16%]
tests/test_error_handler.py::TestErrorHandler::test_get_retry_delay PASSED [ 16%]
tests/test_indexer.py::TestIndexerService::test_initialization PASSED    [ 16%]
tests/test_indexer.py::TestIndexerService::test_get_last_processed_height_no_blocks PASSED [ 16%]
tests/test_indexer.py::TestIndexerService::test_get_last_processed_height_with_blocks PASSED [ 16%]
tests/test_indexer.py::TestIndexerService::test_determine_start_height_fresh_start PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_determine_start_height_resume PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_is_block_processed_true PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_is_block_processed_false_no_block PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_is_block_processed_false_hash_mismatch PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_verify_chain_continuity_true PASSED [ 17%]
tests/test_indexer.py::TestIndexerService::test_verify_chain_continuity_false PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_detect_reorg_true PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_detect_reorg_false PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_detect_reorg_no_stored_block PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_should_check_reorg_true PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_should_check_reorg_false PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_process_block_transactions_skip_coinbase PASSED [ 18%]
tests/test_indexer.py::TestIndexerService::test_process_block_transactions_with_operations PASSED [ 19%]
tests/test_indexer.py::TestIndexerService::test_process_block_success PASSED [ 19%]
tests/test_indexer.py::TestIndexerService::test_process_block_with_errors PASSED [ 19%]
tests/test_indexer.py::TestIndexerService::test_process_block_rpc_failure PASSED [ 19%]
tests/test_indexer.py::TestIndexerService::test_get_sync_status PASSED   [ 19%]
tests/test_indexer.py::TestIndexerService::test_get_sync_status_synced PASSED [ 19%]
tests/test_indexer.py::TestIndexerService::test_find_common_ancestor PASSED [ 20%]
tests/test_indexer.py::TestIndexerService::test_find_common_ancestor_max_depth PASSED [ 20%]
tests/test_indexer.py::TestIndexerServiceIntegration::test_start_indexing_small_range PASSED [ 20%]
tests/test_indexer.py::TestIndexerServiceIntegration::test_start_indexing_with_reorg PASSED [ 20%]
tests/test_integration.py::TestIntegration::test_complete_token_lifecycle PASSED [ 20%]
tests/test_integration.py::TestIntegration::test_multiple_mints_same_block PASSED [ 20%]
tests/test_integration.py::TestIntegration::test_transfer_entire_balance PASSED [ 21%]
tests/test_integration.py::TestIntegration::test_transfer_amount_exceeding_mint_limit PASSED [ 21%]
tests/test_integration.py::TestIntegration::test_invalid_operations_logged PASSED [ 21%]
tests/test_integration.py::TestIntegration::test_complex_transaction_processing PASSED [ 21%]
tests/test_integration.py::TestIntegration::test_error_handling_during_processing PASSED [ 21%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_early_marketplace_invalid_inputs PASSED [ 21%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_early_marketplace_valid PASSED [ 21%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_new_marketplace_invalid_address_mismatch PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_new_marketplace_valid PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_sighash_extraction PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_empty PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_empty_witness PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_legacy PASSED [ 22%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_malformed_scriptSig PASSED [ 23%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_segwit PASSED [ 23%]
tests/test_marketplace_transfers.py::TestMarketplaceTransfers::test_signature_extraction_taproot PASSED [ 23%]
tests/test_models.py::test_models_import PASSED                          [ 23%]
tests/test_models.py::test_deploy_model PASSED                           [ 23%]
tests/test_models.py::test_balance_model PASSED                          [ 23%]
tests/test_models.py::test_brc20_operation_model PASSED                  [ 23%]
tests/test_models.py::test_brc20_operation_invalid PASSED                [ 24%]
tests/test_models.py::test_processed_block_model PASSED                  [ 24%]
tests/test_models.py::test_critical_rules_compliance PASSED              [ 24%]
tests/test_op_migration.py::TestOpMigration::test_op_model_new_field_names PASSED [ 24%]
tests/test_op_migration.py::TestOpMigration::test_op_model_rejects_old_field_names PASSED [ 24%]
tests/test_op_migration.py::TestOpMigration::test_calculation_service_map_operation_to_op_model PASSED [ 24%]
tests/test_op_migration.py::TestOpMigration::test_data_transformation_service_new_format PASSED [ 25%]
tests/test_op_migration.py::TestOpMigration::test_calculation_service_functions_return_new_format PASSED [ 25%]
tests/test_op_migration.py::TestOpMigration::test_no_extra_fields_in_op_model PASSED [ 25%]
tests/test_op_migration.py::TestOpMigration::test_op_model_serialization PASSED [ 25%]
tests/test_opi_000_implementation.py::TestOpi000Implementation::test_implementation_initialization PASSED [ 25%]
tests/test_opi_000_implementation.py::TestOpi000Implementation::test_parse_operation_minimal_payload PASSED [ 25%]
tests/test_opi_000_implementation.py::TestOpi000Implementation::test_implementation_registration PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_missing_txid PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_missing_block_height PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_missing_both_txid_and_height PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_no_legacy_transfer_found PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_invalid_legacy_event_missing_to_pkscript PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_invalid_recipient_address PASSED [ 26%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_missing_required_fields PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Validation::test_validate_operation_success PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Processing::test_process_operation_no_validated_event PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Processing::test_process_operation_missing_legacy_fields PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Processing::test_process_operation_success PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Processing::test_process_operation_address_extraction_failure PASSED [ 27%]
tests/test_opi_000_implementation.py::TestOpi000Processing::test_process_operation_state_cleanup PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_service_initialization PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_service_initialization_custom_url PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_success PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_no_matching_event PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_wrong_event_type PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_missing_event_data PASSED [ 28%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_api_error PASSED [ 29%]
tests/test_opi_000_implementation.py::TestLegacyTransferService::test_get_transfer_event_for_tx_request_error PASSED [ 29%]
tests/test_opi_000_implementation.py::TestOpi000ErrorHandling::test_validation_error_codes PASSED [ 29%]
tests/test_opi_000_implementation.py::TestOpi000ErrorHandling::test_processing_error_cleanup PASSED [ 29%]
tests/test_opi_000_implementation.py::TestOpi000APIEndpoints::test_get_api_endpoints PASSED [ 29%]
tests/test_opi_000_implementation.py::TestOpi000APIEndpoints::test_list_no_return_transactions_endpoint PASSED [ 29%]
tests/test_opi_000_implementation.py::TestOpi000APIEndpoints::test_list_no_return_transactions_database_error PASSED [ 30%]
tests/test_opi_000_implementation.py::TestOpi000Integration::test_complete_no_return_workflow PASSED [ 30%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_opis_endpoint[sqlite] PASSED [ 30%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_opis_endpoint[postgresql] PASSED [ 30%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_endpoint[sqlite] FAILED [ 30%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_endpoint[postgresql] FAILED [ 30%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_not_found[sqlite] PASSED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_not_found[postgresql] PASSED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_endpoint[sqlite] FAILED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_endpoint[postgresql] FAILED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_with_data[sqlite] FAILED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_with_data[postgresql] FAILED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_pagination[sqlite] FAILED [ 31%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_pagination[postgresql] FAILED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_endpoint[sqlite] FAILED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_endpoint[postgresql] FAILED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_not_found[sqlite] FAILED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_not_found[postgresql] FAILED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_invalid_txid[sqlite] PASSED [ 32%]
tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_invalid_txid[postgresql] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_get_opi_details_database_connection_error[sqlite] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_get_opi_details_database_connection_error[postgresql] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_list_no_return_transactions_invalid_pagination[sqlite] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_list_no_return_transactions_invalid_pagination[postgresql] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_get_opi_details_malformed_opi_id[sqlite] PASSED [ 33%]
tests/test_opi_api.py::TestOPIAPIErrorHandling::test_get_opi_details_malformed_opi_id[postgresql] PASSED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_opis_response_format[sqlite] PASSED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_opis_response_format[postgresql] PASSED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_get_opi_details_response_format[sqlite] FAILED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_get_opi_details_response_format[postgresql] FAILED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_no_return_transactions_response_format[sqlite] FAILED [ 34%]
tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_no_return_transactions_response_format[postgresql] FAILED [ 34%]
tests/test_opi_api.py::TestOPIAPISecurity::test_sql_injection_prevention[sqlite] PASSED [ 35%]
tests/test_opi_api.py::TestOPIAPISecurity::test_sql_injection_prevention[postgresql] PASSED [ 35%]
tests/test_opi_api.py::TestOPIAPISecurity::test_input_validation[sqlite] PASSED [ 35%]
tests/test_opi_api.py::TestOPIAPISecurity::test_input_validation[postgresql] PASSED [ 35%]
tests/test_opi_api.py::TestOPIAPISecurity::test_error_message_sanitization[sqlite] PASSED [ 35%]
tests/test_opi_api.py::TestOPIAPISecurity::test_error_message_sanitization[postgresql] PASSED [ 35%]
tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_success[sqlite] FAILED [ 36%]
tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_success[postgresql] FAILED [ 36%]
tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_database_error[sqlite] FAILED [ 36%]
tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_database_error[postgresql] FAILED [ 36%]
tests/test_opi_framework.py::TestOPIRegistry::test_registry_initialization PASSED [ 36%]
tests/test_opi_framework.py::TestOPIRegistry::test_register_opi PASSED   [ 36%]
tests/test_opi_framework.py::TestOPIRegistry::test_register_opi_duplicate PASSED [ 36%]
tests/test_opi_framework.py::TestOPIRegistry::test_get_opi_case_insensitive PASSED [ 37%]
tests/test_opi_framework.py::TestOPIRegistry::test_get_opi PASSED        [ 37%]
tests/test_opi_framework.py::TestOPIRegistry::test_get_opi_not_found PASSED [ 37%]
tests/test_opi_framework.py::TestOPIRegistry::test_unregister_opi PASSED [ 37%]
tests/test_opi_framework.py::TestOPIRegistry::test_unregister_opi_not_found PASSED [ 37%]
tests/test_opi_framework.py::TestOPIRegistry::test_list_opis PASSED      [ 37%]
tests/test_opi_framework.py::TestOPIInterface::test_opi_interface_implementation PASSED [ 38%]
tests/test_opi_framework.py::TestOPIInterface::test_opi_interface_methods_return_correct_types PASSED [ 38%]
tests/test_opi_framework.py::TestOPIProcessor::test_processor_initialization PASSED [ 38%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_no_return_detection PASSED [ 38%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_no_return_validation_failure PASSED [ 38%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_no_return_processing_success PASSED [ 38%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_no_return_not_registered PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_non_opi_operation PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_missing_op_type PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessor::test_process_if_opi_empty_operation PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessorIntegration::test_process_if_opi_with_real_opi_implementation PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessorIntegration::test_processor_performance PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessorIntegration::test_processor_error_handling PASSED [ 39%]
tests/test_opi_framework.py::TestOPIProcessorIntegration::test_processor_database_session_preservation PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkErrorHandling::test_registry_error_handling PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkErrorHandling::test_processor_error_handling PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkErrorHandling::test_processor_processing_error_handling PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkPerformance::test_registry_performance PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkPerformance::test_processor_performance_with_mocks PASSED [ 40%]
tests/test_opi_framework.py::TestOPIFrameworkPerformance::test_processor_performance_with_validation_failure PASSED [ 41%]
tests/test_opi_integration.py::TestOPIEndToEndWorkflow::test_complete_no_return_workflow_success PASSED [ 41%]
tests/test_opi_integration.py::TestOPIEndToEndWorkflow::test_complete_no_return_workflow_validation_failure PASSED [ 41%]
tests/test_opi_integration.py::TestOPIEndToEndWorkflow::test_complete_no_return_workflow_processing_failure PASSED [ 41%]
tests/test_opi_integration.py::TestOPIEndToEndWorkflow::test_complete_no_return_workflow_state_cleanup PASSED [ 41%]
tests/test_opi_integration.py::TestOPIEndToEndWorkflow::test_complete_no_return_workflow_performance PASSED [ 41%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_integration_with_main_processor PASSED [ 42%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_ignores_non_opi_operations PASSED [ 42%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_validation_result_propagation PASSED [ 42%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_handles_unregistered_opi PASSED [ 42%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_handles_missing_op_type PASSED [ 42%]
tests/test_opi_integration.py::TestOPIProcessorIntegration::test_opi_processor_handles_empty_operation PASSED [ 42%]
tests/test_opi_integration.py::TestOPIStateConsistency::test_opi_implementation_state_cleanup PASSED [ 42%]
tests/test_opi_integration.py::TestOPIStateConsistency::test_opi_implementation_state_cleanup_on_error PASSED [ 43%]
tests/test_opi_integration.py::TestOPIStateConsistency::test_opi_implementation_state_cleanup_on_validation_error PASSED [ 43%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_creation PASSED [ 43%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_required_fields PASSED [ 43%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_json_fields PASSED [ 43%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_optional_fields PASSED [ 43%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_foreign_key_relationship PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_timestamps PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_table_name PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_unique_constraint PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_indexes PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_string_representation PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_data_types PASSED [ 44%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_field_lengths PASSED [ 45%]
tests/test_opi_models.py::TestOPIOperationModel::test_opi_operation_nullable_fields PASSED [ 45%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_creation PASSED [ 45%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_required_fields PASSED [ 45%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_optional_fields PASSED [ 45%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_json_field PASSED [ 45%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_enabled_state PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_version_management PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_timestamps PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_table_name PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_unique_constraint PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_string_representation PASSED [ 46%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_data_types PASSED [ 47%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_field_lengths PASSED [ 47%]
tests/test_opi_models.py::TestOPIConfigurationModel::test_opi_configuration_nullable_fields PASSED [ 47%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_operation_database_insert PASSED [ 47%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_configuration_database_insert PASSED [ 47%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_operation_query_operations PASSED [ 47%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_configuration_query_operations PASSED [ 47%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_operation_unique_constraint_violation PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsDatabaseOperations::test_opi_configuration_unique_constraint_violation PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsRelationships::test_opi_operation_brc20_operation_relationship PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsRelationships::test_opi_operation_foreign_key_null PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsValidation::test_opi_operation_field_validation PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsValidation::test_opi_configuration_field_validation PASSED [ 48%]
tests/test_opi_models.py::TestOPIModelsValidation::test_opi_operation_json_validation PASSED [ 49%]
tests/test_opi_models.py::TestOPIModelsValidation::test_opi_configuration_json_validation PASSED [ 49%]
tests/test_opi_models.py::TestOPIModelsPerformance::test_opi_operation_creation_performance PASSED [ 49%]
tests/test_opi_models.py::TestOPIModelsPerformance::test_opi_configuration_creation_performance PASSED [ 49%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_valid_single PASSED [ 49%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_multiple_rejection PASSED [ 49%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_no_op_return PASSED [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_valid_deploy PASSED    [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_valid_mint PASSED      [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_valid_transfer PASSED  [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_invalid_json PASSED    [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_empty_ticker_invalid PASSED [ 50%]
tests/test_parser.py::TestBRC20Parser::test_parse_zero_ticker_valid PASSED [ 50%]
tests/test_parser.py::TestBRC20Parser::test_validate_ticker_format PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_json_structure_missing_protocol PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_json_structure_invalid_protocol PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_json_structure_missing_operation PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_json_structure_invalid_operation PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_json_structure_missing_ticker PASSED [ 51%]
tests/test_parser.py::TestBRC20Parser::test_validate_deploy_fields_missing_max_supply PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_deploy_fields_invalid_max_supply_type PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_deploy_fields_max_lim_format PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_deploy_fields_mixed_format_error PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_deploy_fields_mixed_format_error_2 PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_mint_fields_missing_amount PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_validate_transfer_fields_missing_amount PASSED [ 52%]
tests/test_parser.py::TestBRC20Parser::test_parse_transaction_complete_valid PASSED [ 53%]
tests/test_parser.py::TestBRC20Parser::test_parse_transaction_multiple_op_returns PASSED [ 53%]
tests/test_parser.py::TestBRC20Parser::test_parse_transaction_invalid_brc20 PASSED [ 53%]
tests/test_parser.py::TestBRC20Parser::test_parse_transaction_no_op_return PASSED [ 53%]
tests/test_parser.py::TestBRC20Parser::test_op_return_size_limit PASSED  [ 53%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_first_position_valid_mint PASSED [ 53%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_first_position_valid_transfer PASSED [ 54%]
tests/test_parser.py::TestBRC20Parser::test_deploy_op_return_any_position_still_valid PASSED [ 54%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_second_position_invalid_mint PASSED [ 54%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_second_position_invalid_transfer PASSED [ 54%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_third_position_invalid PASSED [ 54%]
tests/test_parser.py::TestBRC20Parser::test_extract_op_return_multiple_with_first_invalid PASSED [ 54%]
tests/test_performance.py::test_endpoint_performance[sqlite] FAILED      [ 55%]
tests/test_performance.py::test_endpoint_performance[postgresql] FAILED  [ 55%]
tests/test_performance.py::test_ticker_endpoint_performance[sqlite] FAILED [ 55%]
tests/test_performance.py::test_ticker_endpoint_performance[postgresql] FAILED [ 55%]
tests/test_performance.py::test_address_endpoint_performance[sqlite] FAILED [ 55%]
tests/test_performance.py::test_address_endpoint_performance[postgresql] FAILED [ 55%]
tests/test_performance.py::test_pagination_performance[sqlite] FAILED    [ 55%]
tests/test_performance.py::test_pagination_performance[postgresql] FAILED [ 56%]
tests/test_performance.py::test_concurrent_requests_performance[sqlite] FAILED [ 56%]
tests/test_performance.py::test_concurrent_requests_performance[postgresql] FAILED [ 56%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_success PASSED [ 56%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_duplicate_ticker PASSED [ 56%]
tests/test_processor.py::TestBRC20Processor::test_process_mint_within_limits PASSED [ 56%]
tests/test_processor.py::TestBRC20Processor::test_process_mint_exceeds_supply PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_process_mint_exceeds_per_op_limit PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_mint_op_return_position_before_block_height PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_mint_op_return_position_after_block_height_valid PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_mint_op_return_position_after_block_height_invalid PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_sufficient_balance PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_insufficient_balance PASSED [ 57%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_exceeds_mint_limit PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_allocation_first_standard_output PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_allocation_skip_op_return PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_allocation_multiple_outputs PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_atomic_rollback PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_log_all_operations PASSED [ 58%]
tests/test_processor.py::TestBRC20Processor::test_update_balance_mint PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_update_balance_transfer_debit PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_update_balance_insufficient_funds PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_classify_transfer_type_simple PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_classify_transfer_type_valid_marketplace PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_classify_transfer_type_invalid_marketplace PASSED [ 59%]
tests/test_processor.py::TestBRC20Processor::test_invalid_marketplace_early_return_performance PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_with_type_logging PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_marketplace_transfer_op_return_any_position_valid PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_simple_transfer_op_return_not_first_position_invalid PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_blocked_by_legacy PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_allowed_when_not_on_legacy PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_success_real_integration[sqlite] PASSED [ 60%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_success_real_integration[postgresql] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_blocked_by_legacy_real_integration[sqlite] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_deploy_blocked_by_legacy_real_integration[postgresql] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_mint_real_integration[sqlite] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_mint_real_integration[postgresql] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_real_integration[sqlite] PASSED [ 61%]
tests/test_processor.py::TestBRC20Processor::test_process_transfer_real_integration[postgresql] PASSED [ 62%]
tests/test_reorg_handler.py::TestReorgHandler::test_find_common_ancestor PASSED [ 62%]
tests/test_reorg_handler.py::TestReorgHandler::test_rollback_to_height PASSED [ 62%]
tests/test_reorg_handler.py::TestReorgHandler::test_handle_reorg PASSED  [ 62%]
tests/test_timestamp_fix.py::TestTimestampFix::test_convert_block_timestamp_success PASSED [ 62%]
tests/test_timestamp_fix.py::TestTimestampFix::test_convert_block_timestamp_invalid_type PASSED [ 62%]
tests/test_timestamp_fix.py::TestTimestampFix::test_convert_block_timestamp_negative PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_convert_block_timestamp_before_genesis PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_convert_block_timestamp_far_future PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_process_transaction_with_timestamp PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_process_deploy_with_bitcoin_timestamp PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_log_operation_with_bitcoin_timestamp PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_indexer_processes_block_with_timestamp PASSED [ 63%]
tests/test_timestamp_fix.py::TestTimestampFix::test_indexer_handles_missing_timestamp PASSED [ 64%]
tests/test_timestamp_fix.py::TestTimestampFix::test_timestamp_conversion_performance PASSED [ 64%]
tests/test_timestamp_fix.py::TestTimestampFix::test_known_bitcoin_blocks_timestamps PASSED [ 64%]
tests/test_timestamp_fix.py::TestTimestampFix::test_enterprise_logging_on_errors PASSED [ 64%]
tests/test_timestamp_fix.py::TestTimestampFix::test_process_transaction_invalid_timestamp PASSED [ 64%]
tests/test_timestamp_fix.py::TestTimestampFix::test_log_operation_timestamp_fallback PASSED [ 64%]
tests/test_utxo_resolution.py::test_utxo_resolution_service_get_input_address PASSED [ 65%]
tests/test_utxo_resolution.py::test_processor_get_first_input_address PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_first_input_fallback PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_output_after_op_return PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_first_input_fallback_real_integration[sqlite] PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_first_input_fallback_real_integration[postgresql] PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_output_after_op_return_real_integration[sqlite] PASSED [ 65%]
tests/test_utxo_resolution.py::test_deployer_output_after_op_return_real_integration[postgresql] PASSED [ 66%]
tests/test_utxo_resolution.py::test_transfer_input_resolution_real_integration[sqlite] PASSED [ 66%]
tests/test_utxo_resolution.py::test_transfer_input_resolution_real_integration[postgresql] PASSED [ 66%]
tests/test_validator.py::TestBRC20Validator::test_validate_deploy_new_ticker PASSED [ 66%]
tests/test_validator.py::TestBRC20Validator::test_validate_deploy_existing_ticker PASSED [ 66%]
tests/test_validator.py::TestBRC20Validator::test_validate_deploy_invalid_max_supply PASSED [ 66%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_valid PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_no_deploy PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_exceeds_limit PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_exceeds_max_supply PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_transfer_valid PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_transfer_insufficient_balance PASSED [ 67%]
tests/test_validator.py::TestBRC20Validator::test_validate_transfer_no_deploy PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_validate_transfer_can_exceed_mint_limit PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_validate_output_addresses_valid PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_validate_output_addresses_no_standard_outputs PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_get_first_standard_output_address PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_get_current_supply PASSED [ 68%]
tests/test_validator.py::TestBRC20Validator::test_get_balance PASSED     [ 68%]
tests/test_validator.py::TestBRC20Validator::test_get_balance_not_found PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_get_deploy_record PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_validate_complete_operation_deploy PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_overflow_exact_case PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_overflow_just_under_limit PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_validate_mint_overflow_at_limit PASSED [ 69%]
tests/test_validator.py::TestBRC20Validator::test_get_total_minted_calculation PASSED [ 70%]
tests/test_validator.py::TestBRC20Validator::test_get_total_minted_no_mints PASSED [ 70%]
tests/unit/services/test_bitcoin_rpc.py::test_constructor_missing_url PASSED [ 70%]
tests/unit/services/test_bitcoin_rpc.py::test_constructor_missing_user PASSED [ 70%]
tests/unit/services/test_bitcoin_rpc.py::test_constructor_missing_password PASSED [ 70%]
tests/unit/services/test_bitcoin_rpc.py::test_constructor_placeholder_password PASSED [ 70%]
tests/unit/services/test_bitcoin_rpc.py::test_constructor_url_with_at PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_is_connection_error_all_indicators PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_is_connection_error_negative PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_force_reconnect_sets_rpc_none_and_logs PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_health_check_healthy PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_health_check_interval PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_health_check_unhealthy PASSED [ 71%]
tests/unit/services/test_bitcoin_rpc.py::test_health_check_degraded PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_rpc_connection_healthy PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_rpc_connection_failed_reconnect PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_rpc_connection_auth_error PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_rpc_connection_connection_refused PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_rpc_connection_generic_error PASSED [ 72%]
tests/unit/services/test_bitcoin_rpc.py::test_get_connection_status_all_states PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_best_block_hash_success PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_best_block_hash_jsonrpc_exception PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_count_success PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_count_jsonrpc_exception PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_success PASSED   [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_jsonrpc_exception PASSED [ 73%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_by_height_success PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_by_height_jsonrpc_exception PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_get_raw_transaction_success PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_get_raw_transaction_jsonrpc_exception PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_decode_raw_transaction_success PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_decode_raw_transaction_jsonrpc_exception PASSED [ 74%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_hash_success PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_get_block_hash_jsonrpc_exception PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_get_blockchain_info_success PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_get_network_info_success PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_test_connection_success PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_test_connection_failure PASSED [ 75%]
tests/unit/services/test_bitcoin_rpc.py::test_is_mainnet_true PASSED     [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_is_mainnet_false PASSED    [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_close_sets_rpc_none PASSED [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_reset_connection_sets_rpc_none PASSED [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_retry_on_rpc_error_retries_and_raises PASSED [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_retry_on_rpc_error_succeeds_after_retry PASSED [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_retry_on_rpc_error_jsonrpc_exception PASSED [ 76%]
tests/unit/services/test_bitcoin_rpc.py::test_caplog_structlog_diagnostics PASSED [ 77%]
tests/unit/services/test_cache_service.py::test_get_cache_hit PASSED     [ 77%]
tests/unit/services/test_cache_service.py::test_get_cache_miss PASSED    [ 77%]
tests/unit/services/test_cache_service.py::test_get_cache_error PASSED   [ 77%]
tests/unit/services/test_cache_service.py::test_set_cache_success PASSED [ 77%]
tests/unit/services/test_cache_service.py::test_set_cache_error PASSED   [ 77%]
tests/unit/services/test_cache_service.py::test_delete_cache_success PASSED [ 78%]
tests/unit/services/test_cache_service.py::test_delete_cache_miss PASSED [ 78%]
tests/unit/services/test_cache_service.py::test_delete_cache_error PASSED [ 78%]
tests/unit/services/test_cache_service.py::test_generate_key PASSED      [ 78%]
tests/unit/services/test_calculation_service.py::test_get_all_tickers_with_stats_success PASSED [ 78%]
tests/unit/services/test_calculation_service.py::test_get_all_tickers_with_stats_error PASSED [ 78%]
tests/unit/services/test_calculation_service.py::test_get_ticker_stats_success PASSED [ 78%]
tests/unit/services/test_calculation_service.py::test_get_ticker_stats_not_found PASSED [ 79%]
tests/unit/services/test_calculation_service.py::test_get_ticker_stats_error PASSED [ 79%]
tests/unit/services/test_calculation_service.py::test_get_ticker_holders_success PASSED [ 79%]
tests/unit/services/test_calculation_service.py::test_get_ticker_holders_error PASSED [ 79%]
tests/unit/services/test_calculation_service.py::test_get_ticker_transactions_success PASSED [ 79%]
tests/unit/services/test_calculation_service.py::test_get_ticker_transactions_error PASSED [ 79%]
tests/unit/test_bitcoin.py::test_get_script_type[6a0142-op_return] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[76a91489abcdefabbaabbaabbaabbaabbaabbaabbaabba88ac-p2pkh] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[a91489abcdefabbaabbaabbaabbaabbaabbaabbaabba87-p2sh] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[001489abcdefabbaabbaabbaabbaabbaabbaabbaabba-p2wpkh] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[00208989898989898989898989898989898989898989898989898989898989898989-p2wsh] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[51208989898989898989898989898989898989898989898989898989898989898989-p2tr] PASSED [ 80%]
tests/unit/test_bitcoin.py::test_get_script_type[deadbeef-unknown] PASSED [ 81%]
tests/unit/test_bitcoin.py::test_get_script_type[-unknown] PASSED        [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_p2pkh PASSED [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_p2sh PASSED [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_p2wpkh PASSED [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_p2wsh PASSED [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_p2tr PASSED [ 81%]
tests/unit/test_bitcoin.py::test_extract_address_from_script_invalid PASSED [ 82%]
tests/unit/test_bitcoin.py::test_is_op_return_script_true PASSED         [ 82%]
tests/unit/test_bitcoin.py::test_is_op_return_script_false PASSED        [ 82%]
tests/unit/test_bitcoin.py::test_is_standard_output[76a91489abcdefabbaabbaabbaabbaabbaabbaabbaabba88ac-True] PASSED [ 82%]
tests/unit/test_bitcoin.py::test_is_standard_output[a91489abcdefabbaabbaabbaabbaabbaabbaabbaabba87-True] PASSED [ 82%]
tests/unit/test_bitcoin.py::test_is_standard_output[001489abcdefabbaabbaabbaabbaabbaabbaabbaabba-True] PASSED [ 82%]
tests/unit/test_bitcoin.py::test_is_standard_output[00208989898989898989898989898989898989898989898989898989898989898989-True] PASSED [ 83%]
tests/unit/test_bitcoin.py::test_is_standard_output[51208989898989898989898989898989898989898989898989898989898989898989-True] PASSED [ 83%]
tests/unit/test_bitcoin.py::test_is_standard_output[6a0142-False] PASSED [ 83%]
tests/unit/test_bitcoin.py::test_is_standard_output[deadbeef-False] PASSED [ 83%]
tests/unit/test_bitcoin.py::test_is_standard_output[-False] PASSED       [ 83%]
tests/unit/test_bitcoin.py::test_extract_op_return_data_pushdata PASSED  [ 83%]
tests/unit/test_bitcoin.py::test_extract_op_return_data_pushdata1 PASSED [ 84%]
tests/unit/test_bitcoin.py::test_extract_op_return_data_pushdata2 PASSED [ 84%]
tests/unit/test_bitcoin.py::test_extract_op_return_data_pushdata4 PASSED [ 84%]
tests/unit/test_bitcoin.py::test_extract_op_return_data_invalid PASSED   [ 84%]
tests/unit/test_bitcoin.py::test_extract_sighash_type_valid PASSED       [ 84%]
tests/unit/test_bitcoin.py::test_extract_sighash_type_invalid PASSED     [ 84%]
tests/unit/test_bitcoin.py::test_is_sighash_single_anyonecanpay_true PASSED [ 84%]
tests/unit/test_bitcoin.py::test_is_sighash_single_anyonecanpay_false PASSED [ 85%]
tests/unit/test_bitcoin.py::test_extract_signature_from_input_segwit PASSED [ 85%]
tests/unit/test_bitcoin.py::test_extract_signature_from_input_legacy PASSED [ 85%]
tests/unit/test_bitcoin.py::test_extract_signature_from_input_none PASSED [ 85%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfNa-True] PASSED [ 85%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[3J98t1WpEZ73CNmQviecrnyiWrnqRhWNLy-True] PASSED [ 85%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[bc1qw508d6qejxtdg4y5r3zarvary0c5xw7kygt080-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[bc1qrp33g0q5c5txsp9arysrx4k6zdkfs4n0a6v4a5-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[bc1p5cyxnuxmeuwuvkwfem96lxxss9r9ux0f4d7xw6z0a6v4a5-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[mipcBbFg9gMiCh81Kj8tqqdgoZub1ZJRfn-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[2NBFNJTktNa7GZusGbDbGKRZTxdK9VVez3n-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[tb1qfm6a6v4a5w7kygt080-True] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[x1qw508d6qejxtdg4y5r3zarvary0c5xw7kygt080-False] PASSED [ 86%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[12345-False] PASSED [ 87%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[1A1zP1eP5QGefi2DMPTfTL5SLmv7DivfN-False] PASSED [ 87%]
tests/unit/test_crypto.py::test_is_valid_bitcoin_address[-False] PASSED  [ 87%]
tests/unit/test_crypto.py::test_extract_address_from_script_p2pkh PASSED [ 87%]
tests/unit/test_crypto.py::test_extract_address_from_script_p2sh PASSED  [ 87%]
tests/unit/test_crypto.py::test_extract_address_from_script_p2wpkh PASSED [ 87%]
tests/unit/test_crypto.py::test_extract_address_from_script_p2wsh PASSED [ 88%]
tests/unit/test_crypto.py::test_extract_address_from_script_p2tr PASSED  [ 88%]
tests/unit/test_crypto.py::test_extract_address_from_script_invalid PASSED [ 88%]
tests/unit/test_crypto.py::test_is_op_return_script_true PASSED          [ 88%]
tests/unit/test_crypto.py::test_is_op_return_script_false PASSED         [ 88%]
tests/unit/test_crypto.py::test_extract_op_return_data_pushdata PASSED   [ 88%]
tests/unit/test_crypto.py::test_extract_op_return_data_pushdata1 PASSED  [ 89%]
tests/unit/test_crypto.py::test_extract_op_return_data_pushdata2 PASSED  [ 89%]
tests/unit/test_crypto.py::test_extract_op_return_data_pushdata4 PASSED  [ 89%]
tests/unit/test_crypto.py::test_extract_op_return_data_invalid PASSED    [ 89%]
tests/unit/test_main.py::test_main_continuous_true PASSED                [ 89%]
tests/unit/test_main.py::test_main_continuous_false PASSED               [ 89%]
tests/unit/test_main.py::test_main_exception_handling PASSED             [ 89%]
tests/unit/test_main.py::test_main_logger_configured PASSED              [ 90%]
tests/unit/test_monitoring.py::test_record_block_processed_success PASSED [ 90%]
tests/unit/test_monitoring.py::test_record_block_processed_error PASSED  [ 90%]
tests/unit/test_monitoring.py::test_record_block_processed_exception PASSED [ 90%]
tests/unit/test_monitoring.py::test_record_operation_processed_valid PASSED [ 90%]
tests/unit/test_monitoring.py::test_record_operation_processed_invalid PASSED [ 90%]
tests/unit/test_monitoring.py::test_record_operation_processed_exception PASSED [ 91%]
tests/unit/test_monitoring.py::test_record_query_time_fast PASSED        [ 91%]
tests/unit/test_monitoring.py::test_record_query_time_slow PASSED        [ 91%]
tests/unit/test_monitoring.py::test_record_query_time_exception PASSED   [ 91%]
tests/unit/test_monitoring.py::test_add_warning_and_error PASSED         [ 91%]
tests/unit/test_monitoring.py::test_get_health_status PASSED             [ 91%]
tests/unit/test_monitoring.py::test_get_performance_metrics PASSED       [ 92%]
tests/unit/test_monitoring.py::test_get_database_metrics PASSED          [ 92%]
tests/unit/test_monitoring.py::test_export_metrics PASSED                [ 92%]
tests/unit/test_monitoring.py::test_get_sync_status PASSED               [ 92%]
tests/unit/test_monitoring.py::test_log_system_info PASSED               [ 92%]
tests/unit/test_monitoring.py::test_reset_metrics PASSED                 [ 92%]
tests/unit/test_opi_api.py::TestOpiApi::test_list_opis_success[sqlite] PASSED [ 92%]
tests/unit/test_opi_api.py::TestOpiApi::test_list_opis_success[postgresql] PASSED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_success[sqlite] FAILED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_success[postgresql] FAILED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_not_found[sqlite] PASSED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_not_found[postgresql] PASSED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_success[sqlite] FAILED [ 93%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_success[postgresql] FAILED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_not_found[sqlite] PASSED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_not_found[postgresql] PASSED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_empty[sqlite] FAILED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_empty[postgresql] FAILED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_success[sqlite] FAILED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_success[postgresql] FAILED [ 94%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_not_found[sqlite] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_not_found[postgresql] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_empty[sqlite] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_empty[postgresql] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_case_sensitivity_handling[sqlite] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_case_sensitivity_handling[postgresql] FAILED [ 95%]
tests/unit/test_opi_api.py::TestOpiApi::test_api_error_handling[sqlite] PASSED [ 96%]
tests/unit/test_opi_api.py::TestOpiApi::test_api_error_handling[postgresql] PASSED [ 96%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_processor_initialization PASSED [ 96%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_valid_operation PASSED [ 96%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_invalid_operation PASSED [ 96%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_operation_with_warnings PASSED [ 96%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_operation_not_found PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_operation_exception PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_empty_operation_data PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_none_operation_data PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_operation_without_op_field PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_process_with_state_cleanup PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_cleanup_state PASSED [ 97%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_validation_result_creation PASSED [ 98%]
tests/unit/test_opi_processor.py::TestOpiProcessor::test_validation_result_empty PASSED [ 98%]
tests/unit/test_services_isolated.py::TestLegacyTokenServiceIsolated::test_check_token_exists_found PASSED [ 98%]
tests/unit/test_services_isolated.py::TestLegacyTokenServiceIsolated::test_check_token_exists_not_found PASSED [ 98%]
tests/unit/test_services_isolated.py::TestLegacyTokenServiceIsolated::test_validate_deploy_against_legacy_existing PASSED [ 98%]
tests/unit/test_services_isolated.py::TestLegacyTokenServiceIsolated::test_validate_deploy_against_legacy_new PASSED [ 98%]
tests/unit/test_services_isolated.py::TestTokenSupplyServiceIsolated::test_update_supply_tracking_new_token PASSED [ 99%]
tests/unit/test_services_isolated.py::TestTokenSupplyServiceIsolated::test_update_supply_tracking_existing_token PASSED [ 99%]
tests/unit/test_services_isolated.py::TestBRC20ValidatorIsolated::test_validate_deploy_success PASSED [ 99%]
tests/unit/test_services_isolated.py::TestBRC20ValidatorIsolated::test_validate_deploy_legacy_blocked PASSED [ 99%]
tests/unit/test_services_isolated.py::TestBRC20ValidatorIsolated::test_validate_deploy_legacy_allowed_future PASSED [ 99%]
tests/unit/test_services_isolated.py::TestBRC20ValidatorIsolated::test_validate_mint_success PASSED [ 99%]
tests/unit/test_services_isolated.py::TestBRC20ValidatorIsolated::test_validate_transfer_success PASSED [100%]

=================================== FAILURES ===================================
_______ TestOpiIntegration.test_opi_registration_and_processing[sqlite] ________
tests/integration/test_opi_integration.py:82: in test_opi_registration_and_processing
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
---------------------------- Captured stderr setup -----------------------------
{"test_mode": false, "event": "setup_logging complete", "level": "info", "timestamp": "2025-07-14T20:52:27.167312Z"}
------------------------------ Captured log setup ------------------------------
{"test_mode": false, "event": "setup_logging complete", "level": "info", "timestamp": "2025-07-14T20:52:27.167312Z"}
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi", "status_code": 200, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:29.899468Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi \"HTTP/1.1 200 OK\"", "timestamp": "2025-07-14T20:52:29.900264Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:29.903592Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:29.903957Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi", "status_code": 200, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:29.899468Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi \"HTTP/1.1 200 OK\"", "timestamp": "2025-07-14T20:52:29.900359Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:29.903592Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:29.904092Z", "level": "info"}
_____ TestOpiIntegration.test_opi_registration_and_processing[postgresql] ______
tests/integration/test_opi_integration.py:82: in test_opi_registration_and_processing
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi", "status_code": 200, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.129329Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi \"HTTP/1.1 200 OK\"", "timestamp": "2025-07-14T20:52:30.130238Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.132535Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.132943Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi", "status_code": 200, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.129329Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi \"HTTP/1.1 200 OK\"", "timestamp": "2025-07-14T20:52:30.130335Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.132535Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.133039Z", "level": "info"}
___________ TestOpiIntegration.test_opi_operations_retrieval[sqlite] ___________
tests/integration/test_opi_integration.py:120: in test_opi_operations_retrieval
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.232706Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.233418Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.232706Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.233567Z", "level": "info"}
_________ TestOpiIntegration.test_opi_operations_retrieval[postgresql] _________
tests/integration/test_opi_integration.py:120: in test_opi_operations_retrieval
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.348081Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.348644Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.348081Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.348727Z", "level": "info"}
__________ TestOpiIntegration.test_legacy_transfers_retrieval[sqlite] __________
tests/integration/test_opi_integration.py:138: in test_legacy_transfers_retrieval
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.006, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.380394Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.381045Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.006, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.380394Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.381151Z", "level": "info"}
________ TestOpiIntegration.test_legacy_transfers_retrieval[postgresql] ________
tests/integration/test_opi_integration.py:138: in test_legacy_transfers_retrieval
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.488238Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.488769Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.488238Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.488915Z", "level": "info"}
_____________ TestOpiIntegration.test_opi_case_sensitivity[sqlite] _____________
tests/integration/test_opi_integration.py:171: in test_opi_case_sensitivity
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/opi-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.646158Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.646723Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/opi-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.646158Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.646992Z", "level": "info"}
___________ TestOpiIntegration.test_opi_case_sensitivity[postgresql] ___________
tests/integration/test_opi_integration.py:171: in test_opi_case_sensitivity
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/opi-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.740138Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.740840Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/opi-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.740138Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.740927Z", "level": "info"}
____________ TestOpiIntegration.test_empty_results_handling[sqlite] ____________
tests/integration/test_opi_integration.py:190: in test_empty_results_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.767514Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.768055Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.767514Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.768168Z", "level": "info"}
__________ TestOpiIntegration.test_empty_results_handling[postgresql] __________
tests/integration/test_opi_integration.py:190: in test_empty_results_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.863565Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.864039Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.863565Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.864126Z", "level": "info"}
___________ TestOpiIntegration.test_database_error_handling[sqlite] ____________
tests/integration/test_opi_integration.py:210: in test_database_error_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.890678Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.891136Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.890678Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.891218Z", "level": "info"}
_________ TestOpiIntegration.test_database_error_handling[postgresql] __________
tests/integration/test_opi_integration.py:210: in test_database_error_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.987722Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.988389Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:30.987722Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:30.988469Z", "level": "info"}
___________________________ test_get_tickers[sqlite] ___________________________
tests/test_api_integration.py:25: in test_get_tickers
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:32.193466Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:32.193750Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.194289Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.194695Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:32.193466Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:32.193750Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.194289Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.194776Z", "level": "info"}
_________________________ test_get_tickers[postgresql] _________________________
tests/test_api_integration.py:25: in test_get_tickers
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:32.290699Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:32.290948Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.291476Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.291833Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:32.290699Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:32.290948Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.291476Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.291915Z", "level": "info"}
______________________ test_get_ticker_not_found[sqlite] _______________________
tests/test_api_integration.py:34: in test_get_ticker_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.317484Z"}
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.317846Z"}
{"method": "GET", "path": "/v1/indexer/brc20/MISSING/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.318308Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/MISSING/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.318662Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.317484Z"}
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.317846Z"}
{"method": "GET", "path": "/v1/indexer/brc20/MISSING/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.318308Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/MISSING/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.318741Z", "level": "info"}
____________________ test_get_ticker_not_found[postgresql] _____________________
tests/test_api_integration.py:34: in test_get_ticker_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.422673Z"}
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.422993Z"}
{"method": "GET", "path": "/v1/indexer/brc20/MISSING/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.423500Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/MISSING/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.423866Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.422673Z"}
{"ticker": "MISSING", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('MISSING', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.422993Z"}
{"method": "GET", "path": "/v1/indexer/brc20/MISSING/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.423500Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/MISSING/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.423954Z", "level": "info"}
_______________________ test_get_ticker_success[sqlite] ________________________
tests/test_api_integration.py:52: in test_get_ticker_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.454242Z"}
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.454578Z"}
{"method": "GET", "path": "/v1/indexer/brc20/SATS/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.455122Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/SATS/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.455535Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.454242Z"}
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.454578Z"}
{"method": "GET", "path": "/v1/indexer/brc20/SATS/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.455122Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/SATS/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.455614Z", "level": "info"}
_____________________ test_get_ticker_success[postgresql] ______________________
tests/test_api_integration.py:52: in test_get_ticker_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.555354Z"}
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.555724Z"}
{"method": "GET", "path": "/v1/indexer/brc20/SATS/info", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.556205Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/SATS/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.556640Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:32.555354Z"}
{"ticker": "SATS", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('SATS', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:32.555724Z"}
{"method": "GET", "path": "/v1/indexer/brc20/SATS/info", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.556205Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/SATS/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.556745Z", "level": "info"}
_______________________ test_get_ticker_holders[sqlite] ________________________
tests/test_api_integration.py:77: in test_get_ticker_holders
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.588801Z"}
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.589051Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TEST/holders", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.589499Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TEST/holders \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.589947Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.588801Z"}
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.589051Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TEST/holders", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.589499Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TEST/holders \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.590064Z", "level": "info"}
_____________________ test_get_ticker_holders[postgresql] ______________________
tests/test_api_integration.py:77: in test_get_ticker_holders
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.708802Z"}
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.709105Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TEST/holders", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.709490Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TEST/holders \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.709899Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.708802Z"}
{"ticker": "TEST", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.ticker = ? AND balances.balance != ? AND (balances.balance regexp ?) ORDER BY CAST(balances.balance AS NUMERIC) DESC) AS anon_1]\n[parameters: ('TEST', '0', '^[0-9]+$')]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker holders", "level": "error", "timestamp": "2025-07-14T20:52:32.709105Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TEST/holders", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.709490Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TEST/holders \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.709999Z", "level": "info"}
_____________________ test_get_ticker_transactions[sqlite] _____________________
tests/test_api_integration.py:116: in test_get_ticker_transactions
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker transactions", "level": "error", "timestamp": "2025-07-14T20:52:32.746417Z"}
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker history", "level": "error", "timestamp": "2025-07-14T20:52:32.746663Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TXN/history", "status_code": 500, "process_time": 0.006, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.747190Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TXN/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.747667Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker transactions", "level": "error", "timestamp": "2025-07-14T20:52:32.746417Z"}
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker history", "level": "error", "timestamp": "2025-07-14T20:52:32.746663Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TXN/history", "status_code": 500, "process_time": 0.006, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.747190Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TXN/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.747776Z", "level": "info"}
___________________ test_get_ticker_transactions[postgresql] ___________________
tests/test_api_integration.py:116: in test_get_ticker_transactions
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker transactions", "level": "error", "timestamp": "2025-07-14T20:52:32.851736Z"}
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker history", "level": "error", "timestamp": "2025-07-14T20:52:32.852258Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TXN/history", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.852846Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TXN/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.853478Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker transactions", "level": "error", "timestamp": "2025-07-14T20:52:32.851736Z"}
{"ticker": "TXN", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker history", "level": "error", "timestamp": "2025-07-14T20:52:32.852258Z"}
{"method": "GET", "path": "/v1/indexer/brc20/TXN/history", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.852846Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/TXN/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.853635Z", "level": "info"}
______________________ test_get_address_balances[sqlite] _______________________
tests/test_api_integration.py:129: in test_get_address_balances
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get single address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.880969Z"}
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.881243Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qaddress1/brc20/ADDR/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.881748Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qaddress1/brc20/ADDR/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.882202Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get single address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.880969Z"}
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.881243Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qaddress1/brc20/ADDR/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.881748Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qaddress1/brc20/ADDR/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.882357Z", "level": "info"}
____________________ test_get_address_balances[postgresql] _____________________
tests/test_api_integration.py:129: in test_get_address_balances
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get single address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.988752Z"}
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.989035Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qaddress1/brc20/ADDR/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.989499Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qaddress1/brc20/ADDR/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.990012Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get single address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.988752Z"}
{"address": "bc1qaddress1", "ticker": "ADDR", "error": "(sqlite3.OperationalError) no such table: balances\n[SQL: SELECT balances.id AS balances_id, balances.address AS balances_address, balances.ticker AS balances_ticker, balances.balance AS balances_balance, balances.updated_at AS balances_updated_at \nFROM balances \nWHERE balances.address = ? AND balances.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('bc1qaddress1', 'ADDR', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address balance", "level": "error", "timestamp": "2025-07-14T20:52:32.989035Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qaddress1/brc20/ADDR/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:32.989499Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qaddress1/brc20/ADDR/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:32.990186Z", "level": "info"}
____________________ test_get_address_transactions[sqlite] _____________________
tests/test_api_integration.py:158: in test_get_address_transactions
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:33.024368Z"}
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:33.024610Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qsender/history", "status_code": 500, "process_time": 0.005, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.025107Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qsender/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.025661Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:33.024368Z"}
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:33.024610Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qsender/history", "status_code": 500, "process_time": 0.005, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.025107Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qsender/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.025822Z", "level": "info"}
__________________ test_get_address_transactions[postgresql] ___________________
tests/test_api_integration.py:158: in test_get_address_transactions
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:33.134699Z"}
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:33.134959Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qsender/history", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.135495Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qsender/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.135903Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:33.134699Z"}
{"address": "bc1qsender", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:33.134959Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qsender/history", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.135495Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qsender/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.136051Z", "level": "info"}
__________________________ test_health_check[sqlite] ___________________________
tests/test_api_integration.py:167: in test_health_check
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.159773Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.160029Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.160517Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.160936Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.159773Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.160029Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.160517Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.161067Z", "level": "info"}
________________________ test_health_check[postgresql] _________________________
tests/test_api_integration.py:167: in test_health_check
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.261640Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.346390Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.087, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.347234Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.348150Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.261640Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:33.346390Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.087, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.347234Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.348308Z", "level": "info"}
______________________ test_pagination_validation[sqlite] ______________________
tests/test_api_integration.py:177: in test_pagination_validation
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:33.373055Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:33.373509Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.374036Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=-1 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.374458Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:33.373055Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:33.373509Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.374036Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=-1 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.374574Z", "level": "info"}
____________________ test_pagination_validation[postgresql] ____________________
tests/test_api_integration.py:177: in test_pagination_validation
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:33.465513Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:33.465772Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.466308Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=-1 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.466741Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:33.465513Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:33.465772Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.466308Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=-1 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.466870Z", "level": "info"}
_________________ test_long_ticker_valid_but_not_found[sqlite] _________________
tests/test_api_integration.py:186: in test_long_ticker_valid_but_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:33.501438Z"}
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:33.501681Z"}
{"method": "GET", "path": "/v1/indexer/brc20/VERYLONGTICKER/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.502162Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/VERYLONGTICKER/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.502652Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:33.501438Z"}
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:33.501681Z"}
{"method": "GET", "path": "/v1/indexer/brc20/VERYLONGTICKER/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.502162Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/VERYLONGTICKER/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.502781Z", "level": "info"}
_______________ test_long_ticker_valid_but_not_found[postgresql] _______________
tests/test_api_integration.py:186: in test_long_ticker_valid_but_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:33.620250Z"}
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:33.620581Z"}
{"method": "GET", "path": "/v1/indexer/brc20/VERYLONGTICKER/info", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.621221Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/VERYLONGTICKER/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.621722Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:33.620250Z"}
{"ticker": "VERYLONGTICKER", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('VERYLONGTICKER', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:33.620581Z"}
{"method": "GET", "path": "/v1/indexer/brc20/VERYLONGTICKER/info", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:33.621221Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/VERYLONGTICKER/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:33.621864Z", "level": "info"}
__________ TestOPIAPIEndpoints.test_get_opi_details_endpoint[sqlite] ___________
tests/test_opi_api.py:78: in test_get_opi_details_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.644010Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.644589Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.644010Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.644700Z", "level": "info"}
________ TestOPIAPIEndpoints.test_get_opi_details_endpoint[postgresql] _________
tests/test_opi_api.py:78: in test_get_opi_details_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.799892Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.800543Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.799892Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.800683Z", "level": "info"}
____ TestOPIAPIEndpoints.test_list_no_return_transactions_endpoint[sqlite] _____
tests/test_opi_api.py:96: in test_list_no_return_transactions_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.942656Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.943156Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:38.942656Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:38.943241Z", "level": "info"}
__ TestOPIAPIEndpoints.test_list_no_return_transactions_endpoint[postgresql] ___
tests/test_opi_api.py:96: in test_list_no_return_transactions_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.043715Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.044284Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.043715Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.044424Z", "level": "info"}
____ TestOPIAPIEndpoints.test_list_no_return_transactions_with_data[sqlite] ____
tests/test_opi_api.py:126: in test_list_no_return_transactions_with_data
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.077024Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.077668Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.077024Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.077879Z", "level": "info"}
__ TestOPIAPIEndpoints.test_list_no_return_transactions_with_data[postgresql] __
tests/test_opi_api.py:126: in test_list_no_return_transactions_with_data
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.188338Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.188912Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.188338Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.189066Z", "level": "info"}
___ TestOPIAPIEndpoints.test_list_no_return_transactions_pagination[sqlite] ____
tests/test_opi_api.py:155: in test_list_no_return_transactions_pagination
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.219508Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions?skip=10&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.220100Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.219508Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions?skip=10&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.220231Z", "level": "info"}
_ TestOPIAPIEndpoints.test_list_no_return_transactions_pagination[postgresql] __
tests/test_opi_api.py:155: in test_list_no_return_transactions_pagination
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.317497Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions?skip=10&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.318190Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.317497Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions?skip=10&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.318322Z", "level": "info"}
____ TestOPIAPIEndpoints.test_get_no_return_transfer_data_endpoint[sqlite] _____
tests/test_opi_api.py:183: in test_get_no_return_transfer_data_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.346200Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.346872Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.346200Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.346999Z", "level": "info"}
__ TestOPIAPIEndpoints.test_get_no_return_transfer_data_endpoint[postgresql] ___
tests/test_opi_api.py:183: in test_get_no_return_transfer_data_endpoint
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.444270Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.444877Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.444270Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.445047Z", "level": "info"}
____ TestOPIAPIEndpoints.test_get_no_return_transfer_data_not_found[sqlite] ____
tests/test_opi_api.py:191: in test_get_no_return_transfer_data_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.472371Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.472895Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.472371Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.473032Z", "level": "info"}
__ TestOPIAPIEndpoints.test_get_no_return_transfer_data_not_found[postgresql] __
tests/test_opi_api.py:191: in test_get_no_return_transfer_data_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.581637Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.582317Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:39.581637Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:39.582461Z", "level": "info"}
____ TestOPIAPIResponseFormat.test_get_opi_details_response_format[sqlite] _____
tests/test_opi_api.py:285: in test_get_opi_details_response_format
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.200554Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.201042Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.200554Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.201126Z", "level": "info"}
__ TestOPIAPIResponseFormat.test_get_opi_details_response_format[postgresql] ___
tests/test_opi_api.py:285: in test_get_opi_details_response_format
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.312209Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.312817Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/OPI-000", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.312209Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.312896Z", "level": "info"}
_ TestOPIAPIResponseFormat.test_list_no_return_transactions_response_format[sqlite] _
tests/test_opi_api.py:314: in test_list_no_return_transactions_response_format
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.337302Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.337914Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.337302Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.338067Z", "level": "info"}
_ TestOPIAPIResponseFormat.test_list_no_return_transactions_response_format[postgresql] _
tests/test_opi_api.py:314: in test_list_no_return_transactions_response_format
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.432822Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.433300Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.432822Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.433380Z", "level": "info"}
_ TestOPI000SpecificEndpoints.test_list_no_return_transactions_success[sqlite] _
tests/test_opi_api.py:373: in test_list_no_return_transactions_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.818475Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.818971Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.818475Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.819067Z", "level": "info"}
_ TestOPI000SpecificEndpoints.test_list_no_return_transactions_success[postgresql] _
tests/test_opi_api.py:373: in test_list_no_return_transactions_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.921026Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.921600Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:40.921026Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:40.921686Z", "level": "info"}
_ TestOPI000SpecificEndpoints.test_list_no_return_transactions_database_error[sqlite] _
tests/test_opi_api.py:383: in test_list_no_return_transactions_database_error
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.054044Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.054796Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.054044Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.054879Z", "level": "info"}
_ TestOPI000SpecificEndpoints.test_list_no_return_transactions_database_error[postgresql] _
tests/test_opi_api.py:383: in test_list_no_return_transactions_database_error
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.162671Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.163221Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"method": "GET", "path": "/v1/indexer/brc20/opi/no_return/transactions", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.162671Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.163348Z", "level": "info"}
______________________ test_endpoint_performance[sqlite] _______________________
tests/test_performance.py:15: in test_endpoint_performance
    assert response.status_code in [200, 404]
E   assert 500 in [200, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:41.838554Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:41.839028Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.839458Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.839905Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:41.838554Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:41.839028Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.839458Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.840065Z", "level": "info"}
____________________ test_endpoint_performance[postgresql] _____________________
tests/test_performance.py:15: in test_endpoint_performance
    assert response.status_code in [200, 404]
E   assert 500 in [200, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:41.929516Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:41.929769Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.930287Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.930704Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:41.929516Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:41.929769Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.930287Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.930834Z", "level": "info"}
___________________ test_ticker_endpoint_performance[sqlite] ___________________
tests/test_performance.py:32: in test_ticker_endpoint_performance
    assert response.status_code in [200, 404]
E   assert 500 in [200, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:41.954834Z"}
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:41.955089Z"}
{"method": "GET", "path": "/v1/indexer/brc20/ORDI/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.955596Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/ORDI/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.956087Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:41.954834Z"}
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:41.955089Z"}
{"method": "GET", "path": "/v1/indexer/brc20/ORDI/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:41.955596Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/ORDI/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:41.956229Z", "level": "info"}
_________________ test_ticker_endpoint_performance[postgresql] _________________
tests/test_performance.py:32: in test_ticker_endpoint_performance
    assert response.status_code in [200, 404]
E   assert 500 in [200, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:42.045716Z"}
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:42.046124Z"}
{"method": "GET", "path": "/v1/indexer/brc20/ORDI/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.046590Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/ORDI/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.047008Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker stats", "level": "error", "timestamp": "2025-07-14T20:52:42.045716Z"}
{"ticker": "ORDI", "error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys \nWHERE deploys.ticker = ?\n LIMIT ? OFFSET ?]\n[parameters: ('ORDI', 1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get ticker", "level": "error", "timestamp": "2025-07-14T20:52:42.046124Z"}
{"method": "GET", "path": "/v1/indexer/brc20/ORDI/info", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.046590Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/ORDI/info \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.047140Z", "level": "info"}
__________________ test_address_endpoint_performance[sqlite] ___________________
tests/test_performance.py:49: in test_address_endpoint_performance
    assert response.status_code in [200, 400, 404]
E   assert 500 in [200, 400, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:42.070812Z"}
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:42.071087Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.071663Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.072095Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:42.070812Z"}
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:42.071087Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history", "status_code": 500, "process_time": 0.004, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.071663Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.072182Z", "level": "info"}
________________ test_address_endpoint_performance[postgresql] _________________
tests/test_performance.py:49: in test_address_endpoint_performance
    assert response.status_code in [200, 400, 404]
E   assert 500 in [200, 400, 404]
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:42.159005Z"}
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:42.159243Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.159666Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.160103Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address transactions", "level": "error", "timestamp": "2025-07-14T20:52:42.159005Z"}
{"address": "bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh", "error": "(sqlite3.OperationalError) no such table: brc20_operations\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT brc20_operations.id AS brc20_operations_id, brc20_operations.txid AS brc20_operations_txid, brc20_operations.vout_index AS brc20_operations_vout_index, brc20_operations.operation AS brc20_operations_operation, brc20_operations.ticker AS brc20_operations_ticker, brc20_operations.amount AS brc20_operations_amount, brc20_operations.from_address AS brc20_operations_from_address, brc20_operations.to_address AS brc20_operations_to_address, brc20_operations.block_height AS brc20_operations_block_height, brc20_operations.block_hash AS brc20_operations_block_hash, brc20_operations.tx_index AS brc20_operations_tx_index, brc20_operations.timestamp AS brc20_operations_timestamp, brc20_operations.is_valid AS brc20_operations_is_valid, brc20_operations.error_code AS brc20_operations_error_code, brc20_operations.error_message AS brc20_operations_error_message, brc20_operations.raw_op_return AS brc20_operations_raw_op_return, brc20_operations.parsed_json AS brc20_operations_parsed_json, brc20_operations.is_marketplace AS brc20_operations_is_marketplace, processed_blocks.block_hash AS processed_blocks_block_hash \nFROM brc20_operations JOIN processed_blocks ON brc20_operations.block_height = processed_blocks.height \nWHERE 0 = 1 ORDER BY brc20_operations.block_height DESC, brc20_operations.tx_index DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get address history", "level": "error", "timestamp": "2025-07-14T20:52:42.159243Z"}
{"method": "GET", "path": "/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.159666Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/address/bc1qxy2kgdygjrsqtzq2n0yrf2493p83kkfjhx0wlh/history \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.160238Z", "level": "info"}
_____________________ test_pagination_performance[sqlite] ______________________
tests/test_performance.py:65: in test_pagination_performance
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:42.182876Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:42.183080Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.183440Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=0&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.183848Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:42.182876Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:42.183080Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.002, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.183440Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=0&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.183968Z", "level": "info"}
___________________ test_pagination_performance[postgresql] ____________________
tests/test_performance.py:65: in test_pagination_performance
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:42.285345Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:42.285574Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.286014Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=0&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.286468Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get tickers", "level": "error", "timestamp": "2025-07-14T20:52:42.285345Z"}
{"error": "(sqlite3.OperationalError) no such table: deploys\n[SQL: SELECT count(*) AS count_1 \nFROM (SELECT deploys.id AS deploys_id, deploys.ticker AS deploys_ticker, deploys.max_supply AS deploys_max_supply, deploys.limit_per_op AS deploys_limit_per_op, deploys.deploy_txid AS deploys_deploy_txid, deploys.deploy_height AS deploys_deploy_height, deploys.deploy_timestamp AS deploys_deploy_timestamp, deploys.deployer_address AS deploys_deployer_address, deploys.created_at AS deploys_created_at, deploys.is_legacy_validated AS deploys_is_legacy_validated, deploys.legacy_validation_result AS deploys_legacy_validation_result, deploys.legacy_validation_timestamp AS deploys_legacy_validation_timestamp \nFROM deploys ORDER BY deploys.deploy_height DESC) AS anon_1]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get BRC20 list", "level": "error", "timestamp": "2025-07-14T20:52:42.285574Z"}
{"method": "GET", "path": "/v1/indexer/brc20/list", "status_code": 500, "process_time": 0.003, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.286014Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/list?skip=0&limit=10 \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.286605Z", "level": "info"}
_________________ test_concurrent_requests_performance[sqlite] _________________
tests/test_performance.py:94: in test_concurrent_requests_performance
    assert status_code == 200
E   assert 500 == 200
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new sessionDEBUG: Creating new session

DEBUG: Creating new session
DEBUG: Creating new session
DEBUG: Creating new session
DEBUG: Creating new session
DEBUG: Creating new sessionDEBUG: Creating new session

DEBUG: Creating new session
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.319640Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.319872Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.321496Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.321634Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.323935Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324096Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324619Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324731Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.325481Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.325791Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.327770Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328002Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328420Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328547Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.329143Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.329265Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.330125Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.330739Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.330901Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.331144Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.331368Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.332386Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.333115Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.333428Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334040Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334213Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334686Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334798Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335094Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335234Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335370Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.019, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335506Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.336207Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.337418Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.337692Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.338026Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.337091Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.338443Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.338860Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.339345Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.319640Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.319872Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.321496Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.321634Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.323935Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324096Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324619Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.324731Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.325481Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.325791Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.327770Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328002Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328420Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.328547Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.329143Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.329265Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.330512Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.330739Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.330901Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.331144Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.331368Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.332900Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.333212Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.333556Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334040Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334213Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334686Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.334798Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.018, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335094Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335234Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335370Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.019, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.335506Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.337260Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.337539Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.337886Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.338150Z", "level": "info"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.337091Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.338443Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.339205Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.339471Z", "level": "info"}
_______________ test_concurrent_requests_performance[postgresql] _______________
tests/test_performance.py:94: in test_concurrent_requests_performance
    assert status_code == 200
E   assert 500 == 200
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
DEBUG: Creating new sessionDEBUG: Creating new session

DEBUG: Creating new session
DEBUG: Creating new sessionDEBUG: Creating new sessionDEBUG: Creating new session


DEBUG: Creating new session
DEBUG: Creating new session
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.439352Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.439618Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.440793Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.440937Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.441540Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.441655Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.445775Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.445999Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.446659Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.447048Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.447386Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.448680Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449028Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449166Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449697Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449808Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.450250Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.450373Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.451190Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.451691Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.451932Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452138Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452753Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452874Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.453067Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.453632Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.454568Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.455756Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.455914Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.456402Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.013, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456631Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456751Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.019, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456849Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.457160Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.013, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.457521Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.458148Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459239Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459550Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459880Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.460156Z", "level": "info"}
------------------------------ Captured log call -------------------------------
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.439352Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.439618Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.440793Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.440937Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.441540Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.441655Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.445775Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.445999Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.446659Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.447048Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.447386Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.448817Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449028Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449166Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449697Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.449808Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.450250Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.450373Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.451519Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.451782Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.451932Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452138Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452753Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.452874Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.453067Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.016, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.453632Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.455605Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.456119Z", "level": "info"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.455914Z"}
{"error": "(sqlite3.OperationalError) no such table: processed_blocks\n[SQL: SELECT processed_blocks.height AS processed_blocks_height, processed_blocks.block_hash AS processed_blocks_block_hash, processed_blocks.processed_at AS processed_blocks_processed_at, processed_blocks.tx_count AS processed_blocks_tx_count, processed_blocks.brc20_operations_found AS processed_blocks_brc20_operations_found, processed_blocks.brc20_operations_valid AS processed_blocks_brc20_operations_valid \nFROM processed_blocks ORDER BY processed_blocks.height DESC\n LIMIT ? OFFSET ?]\n[parameters: (1, 0)]\n(Background on this error at: https://sqlalche.me/e/20/e3q8)", "event": "Failed to get indexer status", "level": "error", "timestamp": "2025-07-14T20:52:42.456402Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.013, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456631Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.015, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456751Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.019, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.456849Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.017, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.457160Z"}
{"method": "GET", "path": "/v1/indexer/brc20/status", "status_code": 500, "process_time": 0.013, "event": "Request completed", "level": "info", "timestamp": "2025-07-14T20:52:42.457521Z"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459046Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459382Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.459696Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.460017Z", "level": "info"}
{"event": "HTTP Request: GET http://testserver/v1/indexer/brc20/status \"HTTP/1.1 500 Internal Server Error\"", "timestamp": "2025-07-14T20:52:42.460313Z", "level": "info"}
_________________ TestOpiApi.test_get_opi_info_success[sqlite] _________________
tests/unit/test_opi_api.py:138: in test_get_opi_info_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:45.412475Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.412997Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:45.412475Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.413090Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
_______________ TestOpiApi.test_get_opi_info_success[postgresql] _______________
tests/unit/test_opi_api.py:138: in test_get_opi_info_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:45.520339Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.520824Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:45.520339Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.520915Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
______________ TestOpiApi.test_get_opi_operations_success[sqlite] ______________
tests/unit/test_opi_api.py:172: in test_get_opi_operations_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:45.685708Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.686340Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:45.685708Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.686489Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
____________ TestOpiApi.test_get_opi_operations_success[postgresql] ____________
tests/unit/test_opi_api.py:172: in test_get_opi_operations_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:45.816171Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.816899Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:45.816171Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:45.817027Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
_______________ TestOpiApi.test_get_opi_operations_empty[sqlite] _______________
tests/unit/test_opi_api.py:206: in test_get_opi_operations_empty
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.091691Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.092337Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.091691Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.092470Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
_____________ TestOpiApi.test_get_opi_operations_empty[postgresql] _____________
tests/unit/test_opi_api.py:206: in test_get_opi_operations_empty
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.203533Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.204475Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.203533Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/OPI-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.204615Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/OPI-000 "HTTP/1.1 500 Internal Server Error"[0m
_____________ TestOpiApi.test_get_legacy_transfers_success[sqlite] _____________
tests/unit/test_opi_api.py:217: in test_get_legacy_transfers_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.232525Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.233128Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.232525Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.233256Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
___________ TestOpiApi.test_get_legacy_transfers_success[postgresql] ___________
tests/unit/test_opi_api.py:217: in test_get_legacy_transfers_success
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.326878Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.327655Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.326878Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.327794Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
____________ TestOpiApi.test_get_legacy_transfers_not_found[sqlite] ____________
tests/unit/test_opi_api.py:230: in test_get_legacy_transfers_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.354776Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.355442Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.354776Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.355574Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb "HTTP/1.1 500 Internal Server Error"[0m
__________ TestOpiApi.test_get_legacy_transfers_not_found[postgresql] __________
tests/unit/test_opi_api.py:230: in test_get_legacy_transfers_not_found
    assert response.status_code == 404
E   assert 500 == 404
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.465164Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.465950Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.465164Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.466116Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transfers/bbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbbb "HTTP/1.1 500 Internal Server Error"[0m
______________ TestOpiApi.test_get_legacy_transfers_empty[sqlite] ______________
tests/unit/test_opi_api.py:249: in test_get_legacy_transfers_empty
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.495064Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.003[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.495892Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.495064Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.003[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.496045Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
____________ TestOpiApi.test_get_legacy_transfers_empty[postgresql] ____________
tests/unit/test_opi_api.py:249: in test_get_legacy_transfers_empty
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.597071Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.003[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.597660Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.597071Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/no_return/transactions[0m [36mprocess_time[0m=[35m0.003[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.597795Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/no_return/transactions "HTTP/1.1 500 Internal Server Error"[0m
______________ TestOpiApi.test_case_sensitivity_handling[sqlite] _______________
tests/unit/test_opi_api.py:275: in test_case_sensitivity_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.648146Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/opi-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.648725Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.648146Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/opi-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.648894Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 "HTTP/1.1 500 Internal Server Error"[0m
____________ TestOpiApi.test_case_sensitivity_handling[postgresql] _____________
tests/unit/test_opi_api.py:275: in test_case_sensitivity_handling
    assert response.status_code == 200
E   assert 500 == 200
E    +  where 500 = <Response [500 Internal Server Error]>.status_code
----------------------------- Captured stdout call -----------------------------
DEBUG: Creating new session
----------------------------- Captured stderr call -----------------------------
[2m2025-07-14T20:52:46.769289Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/opi-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.769957Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 "HTTP/1.1 500 Internal Server Error"[0m
------------------------------ Captured log call -------------------------------
[2m2025-07-14T20:52:46.769289Z[0m [[32m[1minfo     [0m] [1mRequest completed             [0m [36mmethod[0m=[35mGET[0m [36mpath[0m=[35m/v1/indexer/brc20/opi/opi-000[0m [36mprocess_time[0m=[35m0.002[0m [36mstatus_code[0m=[35m500[0m
[2m2025-07-14T20:52:46.770059Z[0m [[32m[1minfo     [0m] [1mHTTP Request: GET http://testserver/v1/indexer/brc20/opi/opi-000 "HTTP/1.1 500 Internal Server Error"[0m
=========================== short test summary info ============================
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_registration_and_processing[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_registration_and_processing[postgresql]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_operations_retrieval[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_operations_retrieval[postgresql]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_legacy_transfers_retrieval[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_legacy_transfers_retrieval[postgresql]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_case_sensitivity[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_opi_case_sensitivity[postgresql]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_empty_results_handling[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_empty_results_handling[postgresql]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_database_error_handling[sqlite]
FAILED tests/integration/test_opi_integration.py::TestOpiIntegration::test_database_error_handling[postgresql]
FAILED tests/test_api_integration.py::test_get_tickers[sqlite] - assert 500 =...
FAILED tests/test_api_integration.py::test_get_tickers[postgresql] - assert 5...
FAILED tests/test_api_integration.py::test_get_ticker_not_found[sqlite] - ass...
FAILED tests/test_api_integration.py::test_get_ticker_not_found[postgresql]
FAILED tests/test_api_integration.py::test_get_ticker_success[sqlite] - asser...
FAILED tests/test_api_integration.py::test_get_ticker_success[postgresql] - a...
FAILED tests/test_api_integration.py::test_get_ticker_holders[sqlite] - asser...
FAILED tests/test_api_integration.py::test_get_ticker_holders[postgresql] - a...
FAILED tests/test_api_integration.py::test_get_ticker_transactions[sqlite] - ...
FAILED tests/test_api_integration.py::test_get_ticker_transactions[postgresql]
FAILED tests/test_api_integration.py::test_get_address_balances[sqlite] - ass...
FAILED tests/test_api_integration.py::test_get_address_balances[postgresql]
FAILED tests/test_api_integration.py::test_get_address_transactions[sqlite]
FAILED tests/test_api_integration.py::test_get_address_transactions[postgresql]
FAILED tests/test_api_integration.py::test_health_check[sqlite] - assert 500 ...
FAILED tests/test_api_integration.py::test_health_check[postgresql] - assert ...
FAILED tests/test_api_integration.py::test_pagination_validation[sqlite] - as...
FAILED tests/test_api_integration.py::test_pagination_validation[postgresql]
FAILED tests/test_api_integration.py::test_long_ticker_valid_but_not_found[sqlite]
FAILED tests/test_api_integration.py::test_long_ticker_valid_but_not_found[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_endpoint[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_opi_details_endpoint[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_endpoint[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_endpoint[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_with_data[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_with_data[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_pagination[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_list_no_return_transactions_pagination[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_endpoint[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_endpoint[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_not_found[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIEndpoints::test_get_no_return_transfer_data_not_found[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIResponseFormat::test_get_opi_details_response_format[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIResponseFormat::test_get_opi_details_response_format[postgresql]
FAILED tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_no_return_transactions_response_format[sqlite]
FAILED tests/test_opi_api.py::TestOPIAPIResponseFormat::test_list_no_return_transactions_response_format[postgresql]
FAILED tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_success[sqlite]
FAILED tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_success[postgresql]
FAILED tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_database_error[sqlite]
FAILED tests/test_opi_api.py::TestOPI000SpecificEndpoints::test_list_no_return_transactions_database_error[postgresql]
FAILED tests/test_performance.py::test_endpoint_performance[sqlite] - assert ...
FAILED tests/test_performance.py::test_endpoint_performance[postgresql] - ass...
FAILED tests/test_performance.py::test_ticker_endpoint_performance[sqlite] - ...
FAILED tests/test_performance.py::test_ticker_endpoint_performance[postgresql]
FAILED tests/test_performance.py::test_address_endpoint_performance[sqlite]
FAILED tests/test_performance.py::test_address_endpoint_performance[postgresql]
FAILED tests/test_performance.py::test_pagination_performance[sqlite] - asser...
FAILED tests/test_performance.py::test_pagination_performance[postgresql] - a...
FAILED tests/test_performance.py::test_concurrent_requests_performance[sqlite]
FAILED tests/test_performance.py::test_concurrent_requests_performance[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_success[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_info_success[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_success[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_success[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_empty[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_opi_operations_empty[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_success[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_success[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_not_found[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_not_found[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_empty[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_get_legacy_transfers_empty[postgresql]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_case_sensitivity_handling[sqlite]
FAILED tests/unit/test_opi_api.py::TestOpiApi::test_case_sensitivity_handling[postgresql]
======================= 76 failed, 562 passed in 22.22s ========================
